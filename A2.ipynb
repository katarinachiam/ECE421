{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE421 - A2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoFj63CbuRpT",
        "outputId": "a268b382-52ca-4d44-d1f8-9e1d5a4f0907"
      },
      "source": [
        "#google drive mount to colab statement\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "root = '/content/drive/My Drive/_Y3/ECE421_W/A2'\n",
        "os.chdir(root)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyqPRP5nuau3"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "#starter code given below\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# Load the data\n",
        "def loadData():\n",
        "    with np.load(\"notMNIST.npz\") as data:\n",
        "        Data, Target = data[\"images\"], data[\"labels\"]\n",
        "        np.random.seed(521)\n",
        "        randIndx = np.arange(len(Data))\n",
        "        np.random.shuffle(randIndx)\n",
        "        Data = Data[randIndx] / 255.0\n",
        "        Target = Target[randIndx]\n",
        "        trainData, trainTarget = Data[:10000], Target[:10000]\n",
        "        validData, validTarget = Data[10000:16000], Target[10000:16000]\n",
        "        testData, testTarget = Data[16000:], Target[16000:]\n",
        "    return trainData, validData, testData, trainTarget, validTarget, testTarget\n",
        "\n",
        "\n",
        "# Implementation of a neural network using only Numpy - trained using gradient descent with momentum\n",
        "def convertOneHot(trainTarget, validTarget, testTarget):\n",
        "    newtrain = np.zeros((trainTarget.shape[0], 10))\n",
        "    newvalid = np.zeros((validTarget.shape[0], 10))\n",
        "    newtest = np.zeros((testTarget.shape[0], 10))\n",
        "\n",
        "    for item in range(0, trainTarget.shape[0]):\n",
        "        newtrain[item][trainTarget[item]] = 1\n",
        "    for item in range(0, validTarget.shape[0]):\n",
        "        newvalid[item][validTarget[item]] = 1\n",
        "    for item in range(0, testTarget.shape[0]):\n",
        "        newtest[item][testTarget[item]] = 1\n",
        "    return newtrain, newvalid, newtest\n",
        "\n",
        "\n",
        "def shuffle(trainData, trainTarget):\n",
        "    np.random.seed(421)\n",
        "    randIndx = np.arange(len(trainData))\n",
        "    target = trainTarget\n",
        "    np.random.shuffle(randIndx)\n",
        "    data, target = trainData[randIndx], target[randIndx]\n",
        "    return data, target"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7u-DCr_uyhZ"
      },
      "source": [
        "# 1.1 Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31NiTtaLuzpE"
      },
      "source": [
        "def relu(x):\n",
        "  return (np.maximum(x, 0))\n",
        "\n",
        "def softmax(x):\n",
        "  max_elem = np.amax(x,axis=1) #for overflow purposes\n",
        "  new_x = x - max_elem.reshape(-1,1)\n",
        "  numerator = np.exp(new_x)\n",
        "  denominator = np.sum(np.exp(new_x),axis=1,keepdims=True)\n",
        "  return (numerator/denominator)\n",
        "\n",
        "def computeLayer(X, W, b):\n",
        "  y = np.matmul(X, W) + b\n",
        "  return y\n",
        "\n",
        "def CE(target, prediction):\n",
        "  y_logp = target * np.log(prediction)\n",
        "  persample_loss = np.sum(y_logp, axis = 1)\n",
        "  ave_loss = -np.mean(persample_loss)\n",
        "  return ave_loss\n",
        "\n",
        "def gradCE(target, prediction):\n",
        "  return (prediction-target)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCADaxTnPHge"
      },
      "source": [
        "#1.2 Backpropagation Derivation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzQi23OmW0oM"
      },
      "source": [
        "def backprop(x, x_h, W_o, target, prediction):\n",
        "\n",
        "  gCE = gradCE(target, prediction) #with respect to inputs to the softmax function\n",
        "  dwO = np.dot(np.transpose(x_h), gCE)\n",
        "  dbO_term1 = np.ones((1, target.shape[0]))\n",
        "  dbO = np.matmul(dbO_term1, gCE)\n",
        "\n",
        "  dxHdz = relugrad(x_h)\n",
        "  dwH_term1 = np.matmul(gCE, np.transpose(W_o))\n",
        "  dwH_term2 = dxHdz * dwH_term1\n",
        "  dwH = np.matmul(np.transpose(x), dwH_term2)\n",
        "  dbH_term1 = np.ones((1, x_h.shape[0]))\n",
        "  dbH = np.matmul(dbH_term1, dwH_term2)\n",
        "  #shape verification\n",
        "  '''print(\"shape of dL/dWo: %s\" % (dwO.shape,))\n",
        "  print(\"shape of dL/dbo: %s\" % (dbO.shape,))\n",
        "  print(\"shape of dL/dWH: %s\" % (dwH.shape,))\n",
        "  print(\"shape of dL/dbH: %s\" % (dbH.shape,))'''\n",
        "  return dwO, dbO, dwH, dbH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CGHkOPEuziH"
      },
      "source": [
        "#1.3 Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHNXOFt3uyc_"
      },
      "source": [
        "#helper functions:\n",
        "\n",
        "##gradient of ReLU\n",
        "def relugrad(x):\n",
        "  y = np.where(x>0, 1, 0)\n",
        "  return y\n",
        "\n",
        "##accuracy function\n",
        "def acc(prediction, y):\n",
        "  #need to extract maximum probability of each class\n",
        "  max_pred = np.argmax(prediction, axis = 1)\n",
        "  max_y = np.argmax(y, axis = 1)\n",
        "  correct = (max_pred == max_y).sum()\n",
        "  return correct/y.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AKQ054_YhsH"
      },
      "source": [
        "def train(epochs = 200, hidden_size = 1000, alpha = 0.1*1e-4, gamma = 0.99):\n",
        "    # Your implementation here\n",
        "\n",
        "    np.random.seed(328)\n",
        "\n",
        "    trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
        "\n",
        "    trainTarget, validTarget, testTarget = convertOneHot(trainTarget, validTarget, testTarget)\n",
        "    trainData = trainData.reshape(trainData.shape[0], trainData.shape[1] * trainData.shape[2])\n",
        "    validData = validData.reshape(validData.shape[0], validData.shape[1] * validData.shape[2])\n",
        "    testData = testData.reshape(testData.shape[0], testData.shape[1] * testData.shape[2])\n",
        "    \n",
        "    N = trainData.shape[0] #10000 samples\n",
        "    K = trainTarget[0].shape[0] #10 classes\n",
        "    F = trainData[0].shape[0] #28x28 = 784 features\n",
        "\n",
        "    W_o = np.random.normal(0, 2/(hidden_size + K), (hidden_size, K))\n",
        "    b_o = np.zeros((1, K))\n",
        "    W_h = np.random.normal(0, 2/(F+hidden_size), (F, hidden_size))\n",
        "    b_h = np.zeros((1, hidden_size))\n",
        "\n",
        "    v_W_o = np.full((hidden_size, K), 1e-5)\n",
        "    v_b_o = np.full((1, K), 1e-5)\n",
        "    v_W_h = np.full((F, hidden_size), 1e-5)\n",
        "    v_b_h = np.full((1, hidden_size), 1e-5)\n",
        "\n",
        "    trainLoss = []\n",
        "    validLoss = []\n",
        "    testLoss = []\n",
        "    trainAcc = []\n",
        "    validAcc = []\n",
        "    testAcc = []\n",
        "    \n",
        "    for i in range(epochs):\n",
        "      if i%25 == 0:\n",
        "        print(\"epoch:\", i)\n",
        "      z_h = computeLayer(trainData, W_h, b_h)\n",
        "      x_h = relu(z_h)\n",
        "      z_o = computeLayer(x_h, W_o, b_o)\n",
        "      prediction = softmax(z_o)\n",
        "\n",
        "      Vz_h = computeLayer(validData, W_h, b_h)\n",
        "      Vx_h = relu(Vz_h)\n",
        "      Vz_o = computeLayer(Vx_h, W_o, b_o)\n",
        "      Vprediction = softmax(Vz_o)\n",
        "\n",
        "      Tez_h = computeLayer(testData, W_h, b_h)\n",
        "      Tex_h = relu(Tez_h)\n",
        "      Tez_o = computeLayer(Tex_h, W_o, b_o)\n",
        "      Teprediction = softmax(Tez_o)\n",
        "\n",
        "      trainLoss.append(CE(trainTarget, prediction))\n",
        "      validLoss.append(CE(validTarget, Vprediction))\n",
        "      testLoss.append(CE(testTarget, Teprediction))\n",
        "\n",
        "      trainAcc.append(acc(prediction, trainTarget))\n",
        "      validAcc.append(acc(Vprediction, validTarget))\n",
        "      testAcc.append(acc(Teprediction, testTarget))\n",
        "\n",
        "      dwO, dbO, dwH, dbH = backprop(trainData, x_h, W_o, trainTarget, prediction)\n",
        "      \n",
        "      v_W_o = gamma*v_W_o + alpha*dwO\n",
        "      v_b_o = gamma*v_b_o + alpha*dbO\n",
        "      v_W_h = gamma*v_W_h + alpha*dwH\n",
        "      v_b_h = gamma*v_b_h + alpha*dbH\n",
        "\n",
        "      W_o = W_o - v_W_o\n",
        "      b_o = b_o - v_b_o\n",
        "      W_h = W_h - v_W_h\n",
        "      b_h = b_h - v_b_h\n",
        "      \n",
        "    plot(trainLoss, validLoss, 1) #note: just for plotting purposes\n",
        "    plot(trainAcc, validAcc, 2) \n",
        "    return W_o, b_o\n",
        "\n",
        "def plot(train, valid, fignum):\n",
        "  plt.figure(fignum)\n",
        "  plot1, = plt.plot(train)\n",
        "  plot2, = plt.plot(valid)\n",
        "  plt.xlabel('Epochs')\n",
        "  if fignum == 1:\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss vs. Epochs')\n",
        "  elif fignum == 2:\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy vs. Epochs')\n",
        "  plt.legend([plot1,plot2], ['Training', 'Validation'])\n",
        "  plt.show()\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}